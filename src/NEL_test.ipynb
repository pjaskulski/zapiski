{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ba3afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tekst do weryfikacji działania NEL w spaCy\n",
    "test_text = \"\"\"Gdy car Iwan Groźny ustanowił kaprów z wyraźnym upoważnieniem do walki z polskimi, król, \n",
    "zaniepokojony wielce tą „rzeczą niezwykłą i niebywałą  za przodków jego”, jak określił to wystąpienie rywala \n",
    "na Bałtyku, przeciwstawił nowemu niebezpieczeństwu swą strażniczą armadę, ale jednocześnie  zdecydował się \n",
    "na dyplomatyczne kroki w Moskwie przez posła Michała Haraburdę, którego uzbroił w odpis carskiego listu \n",
    "przypowiedniego.\n",
    "Zygmunt August stawiał także przed swą flotą zadanie obrony wybrzeża i portów w razie napadu nieprzyjacielskiego.\n",
    "Chciał jej przeto użyć, o ileby  Gdańsk dał pomoc, do uderzenia na Duńczyków i opanowania ich okrętów  w czasie \n",
    "postoju floty pod admirałem Frankiem na redzie gdańskiej we wrześniu 1571 roku. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5533d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import random\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.ml.models import load_kb\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae889d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc70c43",
   "metadata": {},
   "source": [
    "Testowane będą dwie postacie występujące w wikidata.org: Zygmunt II August i Iwan Groźny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7510c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = desc_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08873db",
   "metadata": {},
   "source": [
    "Identyfiktory Q każdej postaci zostały odnalezione w wikidata, do dalszego przetwarzania przygotowane zostały słowniki nazw i opisów postaci, w których kluczem są identyfikatory Q. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e286d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict['Q7996'] = 'Iwan Groźny'\n",
    "names_dict['Q54058'] = 'Zygmunt August'\n",
    "desc_dict['Q7996'] = 'car Rosji'\n",
    "desc_dict['Q54058'] = 'król Polski i wielki książę litewski'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cf8d7",
   "metadata": {},
   "source": [
    "Tworzenie obietu bazy wiedzy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91cb05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.kb import KnowledgeBase\n",
    "kb = KnowledgeBase(vocab=nlp.vocab, entity_vector_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f08c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qid, desc in desc_dict.items():\n",
    "    desc_doc = nlp(desc)\n",
    "    desc_enc = desc_doc.vector\n",
    "    kb.add_entity(entity=qid, entity_vector=desc_enc, freq=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54fda28",
   "metadata": {},
   "source": [
    "Do bazy wiedzy dodawane są nazwiska postaci, na początek w takiej formie w jakiej występują w wikidata, \n",
    "takie wystąpienia mają pewną rozpoznawalność stąd wartość probablities = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c445f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "for qid, name in names_dict.items():\n",
    "    kb.add_alias(alias=name, entities=[qid], probabilities=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da55fb",
   "metadata": {},
   "source": [
    "W przypadku artykułu S.Bodniaka nie ma właściwie jakiejś wieloznaczności w encjach osób, Zygmunt August będzie zawsze tym Zygmuntem, królem Polski, Iwan będzie carem Rosji. Większym wyzwaniem byłoby gdyby w tekście występowałby np. Mateusz Scharping jako kaper i inna postać np. Ernest Scharping będącą np. niemieckim dyplomatą, wówczas dla encji bedących samym nawiskiem łączenie z identyfikatorami z wikidata.org musiałoby następować na podstawie kontekstu. Tu jednak nie ma takiej sytuacji, do bazy można natomiast dodać dodatkowe aliasy naszych postaci, również pewnie identyfikowane z elementami wikidata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6f19339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17497991486119362077"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.add_alias(alias=\"Iwan IV\", entities=['Q7996'], probabilities=[1])\n",
    "kb.add_alias(alias=\"Iwan Groźny\", entities=['Q7996'], probabilities=[1])\n",
    "kb.add_alias(alias=\"Zygmunt August\", entities=['Q54058'], probabilities=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f43fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path.cwd().parent / \"output\" / \"nel\"\n",
    "kb.to_disk(output_dir / \"kb_bodniak\")\n",
    "nlp.to_disk(output_dir / \"nlp_bodniak\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87aa3f",
   "metadata": {},
   "source": [
    "Przygotowanie danych treningowych na podstawie próbki zdań z artykułu S. Bodniaka zawierającego wzmianki na temat analizowanych 2 postaci. Dane zawierają ok 30 zdań. Tak jak w przypadku anotacji dla trenowania modelu NER tu również anotacja została przeprowadzona w programie doccano, a dane wyjściowe z doccano wymagały przetworzenia na format oczekiwany przez spaCy (w tym przypadku z pliku .jsonl dane importowane są bezpośrednio do skryptu w pythonie). Ponieważ jednak doccano nie wspiera bezpośrednio anotacji pod kątem NEL, a przynajmniej nie widze takiej opcji, zastosowane zostało małe obejście problemu - ze względu na małą liczbę anotowanych postaci w roli etykiet użyto identyfiktorów QID postaci z wikidata. Interpretacją tak uzyskanych danych zajął się poniższy skrypt.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84974e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = Path.cwd().parent / \"data\" / \"bodniak_nel.jsonl\"\n",
    "with open(dataset_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for line in data:\n",
    "    line = json.loads(line)\n",
    "\n",
    "    text = labels = None\n",
    "    if \"text\" in line:\n",
    "        text = line[\"text\"]\n",
    "    if \"label\" in line:\n",
    "        labels = line[\"label\"]\n",
    "\n",
    "    if text and labels:\n",
    "        ents = []\n",
    "        for start, end, label in labels:\n",
    "            offset = (start, end)\n",
    "            QID = label\n",
    "            entity_label = 'persName'\n",
    "            entities = [(offset[0], offset[1], entity_label)]\n",
    "            links_dict = {QID: 1.0}\n",
    "            dataset.append((text, {\"links\": {offset: links_dict}, \"entities\": entities}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f906f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Otóż słaby stan zatrudnienia gdańskiej marynarki handlowej ułatwił niewątpliwie Zygmuntowi Augustowi tworzenie straży morskiej.', {'links': {(80, 100): {'Q54058': 1.0}}, 'entities': [(80, 100, 'persName')]})\n"
     ]
    }
   ],
   "source": [
    "print(dataset[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240365be",
   "metadata": {},
   "source": [
    "Mając przygotowany do trenowania dataset należy go podzielić na cześć treingową i część walidującą, zwykle 20 % zbioru wystarcza do walidacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4ee43c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = names_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19f316ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Q54058': 15, 'Q7996': 15})\n"
     ]
    }
   ],
   "source": [
    "gold_ids = []\n",
    "for text, annot in dataset:\n",
    "    for span, links_dict in annot[\"links\"].items():\n",
    "        for link, value in links_dict.items():\n",
    "            if value:\n",
    "                gold_ids.append(link)\n",
    "\n",
    "print(Counter(gold_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dda08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "test_dataset = []\n",
    "for QID in qids:\n",
    "    indices = [i for i, j in enumerate(gold_ids) if j == QID]\n",
    "    max_ind = len(indices) - 3\n",
    "    train_dataset.extend(dataset[index] for index in indices[0:max_ind])  # wszystkie poza ostatnimi dwoma do zbioru treningowego\n",
    "    test_dataset.extend(dataset[index] for index in indices[max_ind:len(indices)])  # ostanie dwa do zbioru testowego\n",
    "    \n",
    "random.shuffle(train_dataset)\n",
    "random.shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45126ac5",
   "metadata": {},
   "source": [
    "Przygotowanie do trenowania modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b342d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EXAMPLES = []\n",
    "if \"sentencizer\" not in nlp.pipe_names:\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "sentencizer = nlp.get_pipe(\"sentencizer\")\n",
    "for text, annotation in train_dataset:\n",
    "    example = Example.from_dict(nlp.make_doc(text), annotation)\n",
    "    example.reference = sentencizer(example.reference)\n",
    "    TRAIN_EXAMPLES.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4d5cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_linker = nlp.add_pipe(\"entity_linker\", config={\"incl_prior\": False}, last=True)\n",
    "entity_linker.initialize(get_examples=lambda: TRAIN_EXAMPLES, kb_loader=load_kb(output_dir / \"kb_bodniak\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "180a0250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Losses {'entity_linker': 4.341289937496185}\n",
      "50 Losses {'entity_linker': 0.17442050576210022}\n",
      "100 Losses {'entity_linker': 0.21613184611002603}\n",
      "150 Losses {'entity_linker': 0.5162582596143086}\n",
      "200 Losses {'entity_linker': 0.744226594765981}\n",
      "250 Losses {'entity_linker': 0.3348371287186941}\n",
      "300 Losses {'entity_linker': 0.15559369325637817}\n",
      "350 Losses {'entity_linker': 0.49064404765764874}\n",
      "400 Losses {'entity_linker': 0.3006354868412018}\n",
      "450 Losses {'entity_linker': 0.0626627008120219}\n",
      "499 Losses {'entity_linker': 0.5674233635266622}\n"
     ]
    }
   ],
   "source": [
    "with nlp.select_pipes(enable=[\"entity_linker\"]):   # tylko komponent entity linker\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(500): \n",
    "        random.shuffle(TRAIN_EXAMPLES)\n",
    "        batches = minibatch(TRAIN_EXAMPLES, size=compounding(4.0, 32.0, 1.001))\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            nlp.update(\n",
    "                batch,   \n",
    "                drop=0.2,\n",
    "                losses=losses,\n",
    "                sgd=optimizer,\n",
    "            )\n",
    "        if itn % 50 == 0:\n",
    "            print(itn, \"Losses\", losses)\n",
    "print(itn, \"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9cf70903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iwan Groźny persName Q7996\n",
      "Zygmunt August persName Q54058\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test_text)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'persName' and ent.kb_id_ != 'NIL':\n",
    "        print(ent.text, ent.label_, ent.kb_id_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d852a",
   "metadata": {},
   "source": [
    "Instalacja biblioteki wikibaseintegrator, do komunikacji z wikidata.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f21eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikibaseintegrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccdbcc",
   "metadata": {},
   "source": [
    "Niezbędne importy z bilbioteki i ustawienie parametru USER_AGENT, bez którego wikdata.org nie będzie chciała współpracować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "840a29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikibaseintegrator import wbi_helpers\n",
    "from wikibaseintegrator import WikibaseIntegrator\n",
    "from wikibaseintegrator.wbi_config import config as wbi_config\n",
    "\n",
    "wbi_config['USER_AGENT'] = 'MyWikibaseBot/1.0 (https://www.wikidata.org/wiki/User:MyUsername)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60b893",
   "metadata": {},
   "source": [
    "Funkcja wikilinker - proste wyszukiwanie postaci w wikidata.org (w polskiej wersji tego serwisu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca587966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikilinker(search_entity:str, min_year: int, max_year: int, number_of_candidates=10) -> str:\n",
    "    \"\"\" funkcja wyszukuje w wikidata.org identyfikator najlepiej pasujący do postaci \"\"\"\n",
    "    wbi = WikibaseIntegrator()\n",
    "    lista_qid = wbi_helpers.search_entities(search_entity, language='pl', search_type='item', max_results=number_of_candidates, allow_anonymous=True)\n",
    "\n",
    "    best_qid = ''\n",
    "    for item_qid in lista_qid:\n",
    "        my_item = wbi.item.get(entity_id=item_qid)\n",
    "        label = my_item.labels.get(language='pl')\n",
    "        claims = my_item.claims.claims\n",
    "        if 'P31' in claims:\n",
    "            list_instance_of = claims.get('P31')\n",
    "            for item_instance_of in list_instance_of:\n",
    "                instance_of_value = item_instance_of.mainsnak.datavalue['value']['id']\n",
    "                if instance_of_value == 'Q5':\n",
    "                    if 'P570' in claims:\n",
    "                        list_date_death = claims.get('P570')\n",
    "                        for item_date_death in list_date_death:\n",
    "                            date_death_value = item_date_death.mainsnak.datavalue['value']['time']\n",
    "                            if len(date_death_value) > 5:\n",
    "                                year = date_death_value[1:5]\n",
    "                                if year.isdigit():\n",
    "                                    year_int = int(year)\n",
    "                                    if year_int >= min_year and year_int <= max_year:\n",
    "                                        best_qid = item_qid\n",
    "                                        break\n",
    "\n",
    "    return best_qid\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a0938a",
   "metadata": {},
   "source": [
    "Test funkcji wikilinker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b704c5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q7996'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikilinker('Iwan Groźny', 1501, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3c5c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"Już od czerwca bawił król Zygmunt August w pomorskiej  ziemi, lipiec i sierpień spędził w Gdańsku, \n",
    "we wrześniu po kilkudniowym  pobycie w Malborgu w czasie sejmiku podążył do Królewca na zaproszenie ks. Albrechta. \n",
    "Towarzyszyli mu w podróży hetman Jan Tarnowski , marszałek koronny Piotr Kmita, bp. Stanisław Hozjusz, kanclerz \n",
    "Jan Ocieski, podkanclerzy Jan Przerębski i inni przedniejsi senatorowie i dostojnicy polscy obok przedstawicieli \n",
    "świata umysłowego w osobach Marcina Kromera, Szymona Maricjusa-Czystochlebskiego i Łukasza Górnickiego.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48171cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zygmunt August persName Q54058\n",
      "Albrechta persName Q40433\n",
      "Jan Tarnowski persName Q970324\n",
      "Piotr Kmita persName Q355998\n",
      "Stanisław Hozjusz persName Q61962\n",
      "Jan Ocieski persName Q12137032\n",
      "Jan Przerębski persName Q11718767\n",
      "Marcina Kromera persName Q66649\n",
      "Szymona Maricjusa-Czystochlebskiego persName \n",
      "Łukasza Górnickiego persName Q345583\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'persName':\n",
    "        person = ent.lemma_\n",
    "        candidate_qid = wikilinker(person, 1550, 1625)\n",
    "        print(ent.text, ent.label_, candidate_qid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d5dd0",
   "metadata": {},
   "source": [
    "W 9 przypadkach na 10, prosta funkcja wikilinker znalazła prawidłowy identyfikator postaci w wikidata.org, udało \n",
    "się to nawet dla imienia 'Albrechta', zapewne trochę przypadkiem dla podanego zakresu lat (zakresu dla daty śmierci postaci przyjętego na lata 1550-1625 ze względu na znaną tematykę przetwarzanego artykułu) i imienia pierwszy znaleziny element to właśnie Albrecht Hohenzollern. Jedyna nieznaleziona postać to Szymon Maricjus-Czystochlebski - prawdopodobnie jest to Q9352684 (Szymon Marycjusz, alias: Szymon Maricjusz z Pilzna) ale różnica między encją NER w tekście a etykietą w wikidata.org jest zbyt duża by idnetyfikator mógł zostać znaleziony.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18c5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
